{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9090187f",
   "metadata": {},
   "source": [
    "## Analyzing and visualizing proteomics dataset from shotgun and phospho proteome of drug tolerant persisters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f96eff",
   "metadata": {},
   "source": [
    "Conditions: 6 cell line (2 KRAS: H358, H23; 2 EGFR: PC9, H1975, ALK: H2228, H3122), 3 replicates (TMT-10plex), 3 time-points (day 0, day2 and day9).\n",
    "The data has been analyzed for all 6 globally together; now separating them into genotypes (KRAS: parental vs persister comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6800457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec514a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1946ce14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read the files\n",
    "H358_proteins = pd.read_excel('H358.xlsx')\n",
    "H23_proteins = pd.read_excel('H23.xlsx')\n",
    "H1975_proteins = pd.read_excel('H1975.xlsx')\n",
    "PC9_proteins = pd.read_excel('PC9.xlsx')\n",
    "H3122_proteins = pd.read_excel('H3122.xlsx')\n",
    "H2228_proteins = pd.read_excel('H2228.xlsx')\n",
    "\n",
    "\n",
    "print(H358_proteins.head(20))\n",
    "print(H23_proteins.head(20))\n",
    "print (H1975_proteins.head(20))\n",
    "print (PC9_proteins.head(20))\n",
    "print (H3122_proteins.head(20))\n",
    "print (H2228_proteins.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make copy of the dataframes\n",
    "H358_proteins_copy = H358_proteins.copy()\n",
    "H23_proteins_copy = H23_proteins.copy()\n",
    "H1975_proteins_copy = H1975_proteins.copy()\n",
    "PC9_proteins_copy = PC9_proteins.copy()\n",
    "H3122_proteins_copy = H3122_proteins.copy()\n",
    "H2228_proteins_copy = H2228_proteins.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9509c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize the regular expression pattern to extract gene names without _HUMAN\n",
    "pattern = r'\\|([A-Z0-9_]+)\\|([A-Z0-9_]+)_HUMAN'\n",
    "# Define a function to extract gene names from the string and remove _HUMAN\n",
    "def extract_gene_names(input_string):\n",
    "\n",
    "    gene_names = re.findall(pattern, input_string)\n",
    "    if gene_names:\n",
    "        return [name[1] for name in gene_names]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530fe7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the regex to the column names\n",
    "\n",
    "\n",
    "H358_proteins['Protein_name'] = H358_proteins['Protein'].apply(extract_gene_names)\n",
    "H23_proteins['Protein_name'] = H23_proteins['Protein'].apply(extract_gene_names)\n",
    "H1975_proteins['Protein_name'] = H1975_proteins['Protein'].apply(extract_gene_names)\n",
    "PC9_proteins['Protein_name'] = PC9_proteins['Protein'].apply(extract_gene_names)\n",
    "H3122_proteins['Protein_name'] = H3122_proteins['Protein'].apply(extract_gene_names)\n",
    "H2228_proteins['Protein_name'] = H2228_proteins['Protein'].apply(extract_gene_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1234c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "H358_proteins.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6e1ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "H358_proteins_x = H358_proteins.explode('Protein_name')\n",
    "H358_proteins_x.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51ee14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "H23_proteins_x = H23_proteins.explode('Protein_name')\n",
    "H23_proteins_x.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17cada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other cell lines explode\n",
    "H1975_proteins_x = H1975_proteins.explode('Protein_name')\n",
    "PC9_proteins_x = PC9_proteins.explode('Protein_name')\n",
    "H3122_proteins_x = H3122_proteins.explode('Protein_name')\n",
    "H2228_proteins_x = H2228_proteins.explode('Protein_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42ca8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#H358_proteins_x.to_excel('H358_proteins_x.xlsx')\n",
    "#H23_proteins_x.to_excel('H23_proteins_x.xlsx')\n",
    "H1975_proteins_x.to_excel('H1975_proteins_x.xlsx')\n",
    "PC9_proteins_x.to_excel('PC9_proteins_x.xlsx')\n",
    "H3122_proteins_x.to_excel('H3122_proteins_x.xlsx')\n",
    "H2228_proteins_x.to_excel('H2228_proteins_x.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "H358_proteins_x[\"Condition\"].unique()\n",
    "H23_proteins_x[\"Condition\"].unique()\n",
    "H1975_proteins_x[\"Condition\"].unique()\n",
    "PC9_proteins_x[\"Condition\"].unique()\n",
    "H3122_proteins_x[\"Condition\"].unique()\n",
    "H2228_proteins_x[\"Condition\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904120b",
   "metadata": {},
   "source": [
    "Now we have to separate the conditions into different columns: two ways to do it- pivot table and one hot encoding. Examples below: import pandas as pd\n",
    "\n",
    "##### Pivot table: generating ones\n",
    "\n",
    "###### Sample DataFrame\n",
    "data = {'Unique_Column': ['Value1', 'Value2', 'Value3', 'Value1', 'Value3']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "###### Use groupby to generate 3 new columns based on the unique values\n",
    "grouped_df = df.groupby(df.index)['Unique_Column'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "print(grouped_df)\n",
    "\n",
    "##### Using groupby\n",
    "\n",
    "###### Sample DataFrame\n",
    "data = {'Unique_Column': ['Value1', 'Value2', 'Value3', 'Value1', 'Value3']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "###### Create a new column \"Indicator\" to indicate the presence of unique values\n",
    "df['Indicator'] = 1\n",
    "\n",
    "###### Use pivot_table to generate 3 new columns based on the unique values\n",
    "pivot_df = df.pivot_table(index=df.index, columns='Unique_Column', values='Indicator', fill_value=0)\n",
    "\n",
    "print(pivot_df)\n",
    "\n",
    "\n",
    "##### ONE hot Encoding: generating zeros\n",
    "import pandas as pd\n",
    "\n",
    "###### Sample DataFrame\n",
    "data = {'Unique_Column': ['Value1', 'Value2', 'Value3', 'Value1', 'Value3']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "###### Use one hot encoding to create new columns based on unique values\n",
    "one_hot_encoded = pd.get_dummies(df['Unique_Column'])\n",
    "\n",
    "###### Concatenate the one hot encoded columns with the original DataFrame\n",
    "df_encoded = pd.concat([df, one_hot_encoded], axis=1)\n",
    "\n",
    "###### Drop the original \"Unique_Column\" as it is no longer needed\n",
    "df_encoded.drop('Unique_Column', axis=1, inplace=True)\n",
    "\n",
    "print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0749b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pivot table: circumvents the groupby issue\n",
    "H358_proteins_pivot = H358_proteins_x.pivot_table(index= ['Protein', 'Protein_name'], columns='Condition', values='Abundance', aggfunc='mean')\n",
    "H23_proteins_pivot = H23_proteins_x.pivot_table(index= ['Protein', 'Protein_name'], columns='Condition', values='Abundance', aggfunc='mean')\n",
    "H1975_proteins_pivot = H1975_proteins_x.pivot_table(index= ['Protein', 'Protein_name'], columns='Condition', values='Abundance', aggfunc='mean')\n",
    "PC9_proteins_pivot = PC9_proteins_x.pivot_table(index= ['Protein', 'Protein_name'], columns='Condition', values='Abundance', aggfunc='mean')\n",
    "H3122_proteins_pivot = H3122_proteins_x.pivot_table(index= ['Protein', 'Protein_name'], columns='Condition', values='Abundance', aggfunc='mean')\n",
    "H2228_proteins_pivot = H2228_proteins_x.pivot_table(index= ['Protein', 'Protein_name'], columns='Condition', values='Abundance', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23004e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the two dataframes\n",
    "merged_df = H358_proteins_pivot.merge(H23_proteins_pivot, on='Protein_name', how='outer') \\\n",
    "           .merge(H1975_proteins_pivot, on='Protein_name', how='outer') \\\n",
    "           .merge(PC9_proteins_pivot, on='Protein_name', how='outer') \\\n",
    "           .merge(H3122_proteins_pivot, on='Protein_name', how='outer') \\\n",
    "           .merge(H2228_proteins_pivot, on='Protein_name', how='outer')\n",
    "\n",
    "merged_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c8e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the NaN values with 0\n",
    "merged_df = merged_df.fillna(0)\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e873811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index\n",
    "merged_df_ri = merged_df.reset_index().sort_values(by= \"Protein_name\")\n",
    "merged_df_ri.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide index\n",
    "merged_df_ri.style.hide_index() \n",
    "merged_df_ri.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8fa314",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= merged_df_ri.columns[1:] \n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4ffb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the distribution of the data\n",
    "cols= merged_df_ri.columns[1:] \n",
    "for col in cols:\n",
    "    sns.kdeplot(merged_df_ri[col], shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b8a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 1\n",
    "num_cols = len(cols)\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(15, 5))\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    sns.kdeplot(merged_df_ri[col], shade=True, ax=axes[i])\n",
    "    axes[i].set_xlabel('X-axis Label')  # Customize the x-axis label (optional)\n",
    "    axes[i].set_ylabel('Density')  # Customize the y-axis label (optional)\n",
    "    axes[i].set_title(col)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7f2ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(merged_df_ri, diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfda849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas profiling\n",
    "import pandas_profiling\n",
    "merged_df_ri.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2712a5",
   "metadata": {},
   "source": [
    "#### P-VALUE turned out to be not so meaningful (ERROR in p value calculation; correction below), the dynamic range is very thin; try a median normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570f87a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up control\n",
    "merged_df_ri['Control_aggregate']= merged_df_ri[['DMSO_H358', 'DMSO_H23', 'DMSO_H1975', 'DMSO_PC9', 'DMSO_H3122', 'DMSO_H2228']].mean(axis=1)\n",
    "\n",
    "# Setting up treatment\n",
    "merged_df_ri['Treatment_aggregate']= merged_df_ri[['Osi_d2_H358', 'Osi_d9_H358','Osi_d2_H23', 'Osi_d9_H23', 'Osi_d2_H1975', 'Osi_d9_H1975', 'Osi_d2_PC9', 'Osi_d9_PC9', 'Osi_d2_H3122', 'Osi_d9_H3122', 'Osi_d2_H2228', 'Osi_d9_H2228']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b2824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_ri.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f2d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Std deviation\n",
    "merged_df_ri['Control_std']= merged_df_ri[['DMSO_H358', 'DMSO_H23', 'DMSO_H1975', 'DMSO_PC9', 'DMSO_H3122', 'DMSO_H2228']].std(axis=1)\n",
    "merged_df_ri['Treatment_std']= merged_df_ri[['Osi_d2_H358', 'Osi_d9_H358','Osi_d2_H23', 'Osi_d9_H23', 'Osi_d2_H1975', 'Osi_d9_H1975', 'Osi_d2_PC9', 'Osi_d9_PC9', 'Osi_d2_H3122', 'Osi_d9_H3122', 'Osi_d2_H2228', 'Osi_d9_H2228']].std(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7da8ad",
   "metadata": {},
   "source": [
    "#### Same issue with the p value;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadac81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually generating p-value\n",
    "#Formula: Control_mean - Treated_mean / sqrt((Control_std^2 / n) + (Treated_std^2 / n))\n",
    "test_stats = []\n",
    "for gene in merged_df_ri.index:\n",
    "    test_stat = (merged_df_ri.loc[gene, 'Control_aggregate'] - merged_df_ri.loc[gene, 'Treatment_aggregate']) / np.sqrt((merged_df_ri.loc[gene, 'Control_std']**2 / 2) + (merged_df_ri.loc[gene, 'Treatment_std']**2 / 4))\n",
    "    test_stats.append(test_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_ri['test_stats'] = test_stats\n",
    "merged_df_ri.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c1fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying a for loop\n",
    "df = merged_df_ri\n",
    "\n",
    "# Separate the treated and untreated cohorts\n",
    "untreated_samples = ['DMSO_H358', 'DMSO_H23', 'DMSO_H1975', 'DMSO_PC9', 'DMSO_H3122', 'DMSO_H2228']  \n",
    "treated_samples = ['Osi_d2_H358', 'Osi_d9_H358','Osi_d2_H23', 'Osi_d9_H23', 'Osi_d2_H1975', 'Osi_d9_H1975', 'Osi_d2_PC9', 'Osi_d9_PC9', 'Osi_d2_H3122', 'Osi_d9_H3122', 'Osi_d2_H2228', 'Osi_d9_H2228']  \n",
    "\n",
    "# Create separate DataFrames for treated and untreated cohorts\n",
    "treated_df = df[treated_samples]\n",
    "untreated_df = df[untreated_samples]\n",
    "\n",
    "# Calculate the mean expression for each gene in treated and untreated cohorts\n",
    "mean_treated = treated_df.mean(axis=1)\n",
    "mean_untreated = untreated_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87c39b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_treated.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e5afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_untreated.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate LogFC\n",
    "logFC = np.log2(mean_treated / mean_untreated)\n",
    "\n",
    "# Calculate the absolute LogFC\n",
    "abs_logFC = np.abs(logFC)\n",
    "abs_logFC.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c5f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a statistical test (e.g., t-test) for each gene\n",
    "p_values = []\n",
    "for gene in df.index:\n",
    "    _, p_value = stats.ttest_ind(treated_df.loc[gene], untreated_df.loc[gene])\n",
    "    p_values.append(p_value)\n",
    "    \n",
    "p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2235de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the first few p-values\n",
    "print (p_values[:10])\n",
    "print (len(p_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4071deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9916e05d",
   "metadata": {},
   "source": [
    "#### So, the issue is with the multiple hypothesis testing; Let's try to manually do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cbc6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of genes (N)\n",
    "total_genes = len(p_values)\n",
    "\n",
    "# Calculate the ranks of p-values\n",
    "ranked_p_values = np.argsort(p_values) + 1\n",
    "\n",
    "# Calculate padj for each gene\n",
    "padj = [p * (total_genes / rank) for p, rank in zip(p_values, ranked_p_values)]\n",
    "\n",
    "# Make sure padj values are not greater than 1\n",
    "padj = [min(p, 1.0) for p in padj]\n",
    "\n",
    "print (padj)\n",
    "print (len(padj))\n",
    "print (min(padj))\n",
    "print (max(padj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['padj'] = padj\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a807cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Significant']= df['padj'] < 0.05\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7162c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter differentially expressed genes based on significance level (e.g., padj < 0.05)\n",
    "DEG = df[df['Significant'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEG.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b1e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90066aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEG[\"FDR\"] = DEG[\"padj\"].apply(lambda x: -1 * (x if x > 0 else 1e-300)).apply(lambda x: -1 * (x if x < 1 else 1))\n",
    "DEG.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fb3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dtype in DEG FDR column\n",
    "DEG.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0106e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEG['-Log10FDR'] = -1* np.log10(DEG['FDR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8253d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEG.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde7a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a volcano plot\n",
    "# Define the threshold for log fold change\n",
    "\n",
    "logFC_threshold = 0.05\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(DEG[\"LogFC\"], DEG[\"-Log10FDR\"], c=\"blue\", edgecolors=\"black\", alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Log Fold Change (LogFC)\")\n",
    "plt.ylabel(\"-log10(False Discovery Rate) FDR\")\n",
    "plt.title(\"Volcano Plot\")\n",
    "\n",
    "significant_logfc_threshold = 0.05\n",
    "significant_fdr_threshold = -1 * (1 / 1000)  # Equivalent to FDR = 0.001\n",
    "plt.axvline(significant_logfc_threshold, color=\"red\", linestyle=\"--\", label=\"LogFC Threshold\")\n",
    "plt.axhline(significant_fdr_threshold, color=\"green\", linestyle=\"--\", label=\"-log10(FDR) Threshold\")\n",
    "\n",
    "# Add gene labels\n",
    "for i, row in DEG.iterrows():\n",
    "    plt.text(row[\"LogFC\"], row[\"-Log10FDR\"], row[\"Protein_name\"], ha='left', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357005d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEG_heatmap = DEG.iloc[:,0:19]\n",
    "DEG_heatmap.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80003a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEG_heatmap.set_index('Protein_name', inplace=True)\n",
    "DEG_heatmap.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00016c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEG_heatmap.to_excel('DEG_heatmap_all.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73705e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the data\n",
    "sns.heatmap(DEG_heatmap, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustermap of the data\n",
    "sns.clustermap(DEG_heatmap, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a765600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show all the gene names in the heatmap with small font size\n",
    "sns.set(font_scale=1)\n",
    "sns.clustermap(DEG_heatmap, cmap=\"YlGnBu\", yticklabels=True, figsize=(50, 50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d14bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the data\n",
    "DEG_heatmap_rc = pd.read_excel('DEG_heatmap_all_organized.xlsx')\n",
    "#reset the index\n",
    "DEG_heatmap_rc.set_index('Protein_name', inplace=True)\n",
    "DEG_heatmap_rc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b03b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just cluster the rows\n",
    "sns.clustermap(DEG_heatmap_rc, cmap=\"YlGnBu\", yticklabels=True, figsize=(50, 50), col_cluster=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
